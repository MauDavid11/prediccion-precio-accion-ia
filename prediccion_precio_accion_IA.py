# -*- coding: utf-8 -*-
"""prediccion_precio_accion_IA2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1agwKZSme8CJ0d1l4BfuLczEl8jeP4eMh

**CODIGO BASE**
"""

# -*- coding: utf-8 -*-
"""prediccion_precio_accion_IA.py"""

# ===========================
# 1. Imports e instalación
# ===========================
!pip install yfinance tensorflow scikit-learn -q

import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import ReduceLROnPlateau

from datetime import date, timedelta
import argparse


plt.rcParams['figure.figsize'] = (12,4)
print("TensorFlow:", tf.__version__)

# ===========================
# 2. Descargar datos (hasta AYER)
# ===========================
# ===========================
# Parámetros por línea de comandos
# ===========================
parser = argparse.ArgumentParser(description="Predicción de precio de cierre con LSTM")

parser.add_argument(
    "--ticker",
    type=str,
    default="AAPL",
    help="Ticker de la acción a predecir (ej: AAPL, MSFT, TSLA)"
)

parser.add_argument(
    "--start_date",
    type=str,
    default="2020-03-01",
    help="Fecha inicial para descargar datos históricos (YYYY-MM-DD)"
)

parser.add_argument(
    "--epochs",
    type=int,
    default=80,
    help="Número de épocas para entrenar el modelo"
)

import sys

# Si estamos en un notebook (ipykernel), ignoramos los argumentos de sistema
if 'ipykernel' in sys.modules:
    args = parser.parse_args(args=[])  # usa solo los defaults o lo que pongas aquí
else:
    args = parser.parse_args()  # modo script normal


ticker = args.ticker
start_date = args.start_date
epochs = args.epochs

# yfinance toma end como EXCLUSIVO → si ponemos hoy, llega hasta ayer
today = date.today()
end_date = today.strftime("%Y-%m-%d")

data = yf.download(ticker, start=start_date, end=end_date)

# Nos quedamos solo con el cierre
data = data[['Close']].copy()

print(data.tail())
print("Número de días:", len(data))
print("Último cierre disponible (debe ser AYER):", data['Close'].iloc[-1])

# ===========================
# 3. Escalado y creación de secuencias (60 días → 1 día)
# ===========================
close_prices = data['Close'].values.reshape(-1,1)

scaler = MinMaxScaler(feature_range=(0,1))
close_scaled = scaler.fit_transform(close_prices)

window_size = 60  # ventana de 60 días, igual que el proyecto de Hugging Face

def create_sequences(series, window):
    X, y = [], []
    for i in range(window, len(series)):
        X.append(series[i-window:i, 0])   # últimos 60 precios
        y.append(series[i, 0])           # siguiente precio
    X = np.array(X)
    y = np.array(y)
    return X, y

X_all, y_all = create_sequences(close_scaled, window_size)

# Reshape para LSTM: (samples, timesteps, features)
X_all = np.expand_dims(X_all, axis=-1)

print("X_all shape:", X_all.shape)  # (n_samples, 60, 1)
print("y_all shape:", y_all.shape)

# ===========================
# 4. Split train / test temporal
# ===========================
train_size = int(len(X_all) * 0.8)

X_train = X_all[:train_size]
y_train = y_all[:train_size]
X_test  = X_all[train_size:]
y_test  = y_all[train_size:]

print("Train:", X_train.shape, "Test:", X_test.shape)

# ===========================
# 5. Definición del modelo LSTM
# ===========================
model = Sequential([
    LSTM(128, return_sequences=True, input_shape=(window_size, 1)),
    Dropout(0.2),
    LSTM(64),
    Dropout(0.2),
    Dense(1)
])

model.compile(
    loss='mean_squared_error',
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)
)

model.summary()

# ===========================
# 6. Entrenamiento
# ===========================
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    verbose=1
)

history = model.fit(
     X_train, y_train,
     epochs=epochs,             # Entrena las 80 épocas, se puede cambiar o implementar EarlyStopping
     batch_size=32,
     validation_split=0.1,
     callbacks=[reduce_lr],  # scheduler
     verbose=1
)

# Curvas de pérdida
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Val')
plt.title("Pérdida durante el entrenamiento")
plt.xlabel("Época")
plt.ylabel("MSE")
plt.legend()
plt.show()

# ===========================
# 7. Predicción en test y BASLINES
# ===========================

# Predicción del LSTM en test (escala [0,1])
y_pred_scaled = model.predict(X_test)

# Desescalar a precios reales
y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
y_test_real = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()

# ---------- Baseline 1: ingenuo (mañana = hoy) ----------
# Para cada día t, la predicción es el valor real del día t-1
# Perdemos el primer punto porque no tiene día anterior en el test
y_test_real_shifted = y_test_real[1:]      # targets desde el segundo día
y_pred_naive = y_test_real[:-1]            # predicción = valor del día previo

mae_naive = mean_absolute_error(y_test_real_shifted, y_pred_naive)
rmse_naive = np.sqrt(mean_squared_error(y_test_real_shifted, y_pred_naive))

# ---------- Baseline 2: media móvil de 5 días ----------
window = 5
ma_preds = []
ma_targets = []

for i in range(window, len(y_test_real)):
    ma_preds.append(y_test_real[i-window:i].mean())  # promedio de los últimos 5 días
    ma_targets.append(y_test_real[i])                # valor real del día i

ma_preds = np.array(ma_preds)
ma_targets = np.array(ma_targets)

mae_ma5 = mean_absolute_error(ma_targets, ma_preds)
rmse_ma5 = np.sqrt(mean_squared_error(ma_targets, ma_preds))

# ---------- Métricas del LSTM ----------
mae_lstm = mean_absolute_error(y_test_real, y_pred)
rmse_lstm = np.sqrt(mean_squared_error(y_test_real, y_pred))

print("===== MÉTRICAS EN TEST =====")
print(f"Baseline ingenuo (mañana = hoy)     -> MAE: {mae_naive:.4f} | RMSE: {rmse_naive:.4f}")
print(f"Baseline media móvil 5 días         -> MAE: {mae_ma5:.4f} | RMSE: {rmse_ma5:.4f}")
print(f"Modelo LSTM                         -> MAE: {mae_lstm:.4f} | RMSE: {rmse_lstm:.4f}")


# Fechas correspondientes al conjunto de test
fechas = data.index[window_size + train_size : window_size + train_size + len(y_test_real)]

plt.figure(figsize=(12,4))
plt.plot(fechas, y_test_real, label="Real")
plt.plot(fechas, y_pred, label="Predicción LSTM")
plt.title(f"Predicción vs Real – LSTM ({ticker}) desde pandemia")
plt.xlabel("Fecha")
plt.ylabel("Precio de cierre")
plt.legend()
plt.show()


# ===========================
# 8. Función para predecir el cierre del próximo día
# ===========================
def predict_next_day_close(last_60_closes):
    """
    last_60_closes: iterable con 60 precios de cierre reales (no escalados).
    Devuelve la predicción del cierre del próximo día.
    """
    arr = np.array(last_60_closes).reshape(-1,1)
    arr_scaled = scaler.transform(arr)
    X_input = arr_scaled.reshape(1, window_size, 1)
    pred_scaled = model.predict(X_input)[0,0]
    pred_price = scaler.inverse_transform([[pred_scaled]])[0,0]
    return pred_price

# Ejemplo usando los últimos 60 días de tu serie (hasta AYER)
ultimos_60 = close_prices[-60:]
prediccion_manana = predict_next_day_close(ultimos_60)

print("Precio de cierre del último día disponible (AYER):", close_prices[-1,0])
print("Predicción de cierre para el próximo día (HOY):", prediccion_manana)

"""✔ Aprende las tendencias

✔ Aprende la forma histórica del precio

✔ Predice valores razonables (sin explosiones raras)

✔ Se comporta como un modelo real de forecasting

✔ La predicción diaria (HOY) tiene sentido económico

✔ Comparación con baselines

✔ Pipeline está bien implementado y reconocible


Conclusion:
“Nuestro modelo LSTM no supera al baseline ingenuo, lo cual es consistente con literatura financiera, pero sí logra capturar tendencias y movimientos importantes. Esto demuestra que los modelos de IA pueden complementar análisis financiero, pero no reemplazan la complejidad del mercado real.”

**SEGMENTACION POR FUNCIONES**
"""

# -*- coding: utf-8 -*-
"""prediccion_precio_accion_IA.py"""

# ===========================
# 1. Imports e instalación
# ===========================
!pip install yfinance tensorflow scikit-learn -q

import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import ReduceLROnPlateau

from datetime import date
import argparse
import sys

plt.rcParams['figure.figsize'] = (12,4)


# ===========================
# 2. Parámetros por línea de comandos
# ===========================
parser = argparse.ArgumentParser(description="Predicción de precio de cierre con LSTM")

parser.add_argument(
    "--ticker",
    type=str,
    default="AAPL",
    help="Ticker de la acción a predecir (ej: AAPL, MSFT, TSLA)"
)

parser.add_argument(
    "--start_date",
    type=str,
    default="2020-03-01",
    help="Fecha inicial para descargar datos históricos (YYYY-MM-DD)"
)

parser.add_argument(
    "--epochs",
    type=int,
    default=80,
    help="Número de épocas para entrenar el modelo"
)

# En notebooks (Colab/Jupyter) ignoramos los argumentos del sistema
if 'ipykernel' in sys.modules:
    args = parser.parse_args(args=[])
else:
    args = parser.parse_args()

TICKER = args.ticker
START_DATE = args.start_date
EPOCHS = args.epochs


# ===========================
# 3. Funciones auxiliares
# ===========================
def create_sequences(series, window):
    """Crea secuencias de longitud 'window' para predicción un paso adelante."""
    X, y = [], []
    for i in range(window, len(series)):
        X.append(series[i-window:i, 0])   # últimos 'window' precios
        y.append(series[i, 0])           # siguiente precio
    X = np.array(X)
    y = np.array(y)
    return X, y


def prepare_data(ticker, start_date, window_size=60):
    """
    Descarga datos hasta AYER, escala, crea secuencias y hace split train/test.
    Devuelve: data, close_prices, scaler, X_train, y_train, X_test, y_test, train_size, window_size
    """
    today = date.today()
    end_date = today.strftime("%Y-%m-%d")  # yfinance usa end como exclusivo → llega hasta ayer

    data = yf.download(ticker, start=start_date, end=end_date)
    data = data[['Close']].copy()

    print(data.tail())
    print("Número de días:", len(data))
    print("Último cierre disponible (debe ser AYER):", data['Close'].iloc[-1])

    close_prices = data['Close'].values.reshape(-1,1)

    scaler = MinMaxScaler(feature_range=(0,1))
    close_scaled = scaler.fit_transform(close_prices)

    X_all, y_all = create_sequences(close_scaled, window_size)
    X_all = np.expand_dims(X_all, axis=-1)  # (n_samples, window_size, 1)

    print("X_all shape:", X_all.shape)
    print("y_all shape:", y_all.shape)

    train_size = int(len(X_all) * 0.8)
    X_train = X_all[:train_size]
    y_train = y_all[:train_size]
    X_test  = X_all[train_size:]
    y_test  = y_all[train_size:]

    print("Train:", X_train.shape, "Test:", X_test.shape)

    return data, close_prices, scaler, X_train, y_train, X_test, y_test, train_size, window_size


def build_model(window_size):
    """Define y compila el modelo LSTM."""
    model = Sequential([
        LSTM(128, return_sequences=True, input_shape=(window_size, 1)),
        Dropout(0.2),
        LSTM(64),
        Dropout(0.2),
        Dense(1)
    ])

    model.compile(
        loss='mean_squared_error',
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)
    )

    return model


def train_model(model, X_train, y_train, epochs):
    """Entrena el modelo LSTM y devuelve el history."""
    reduce_lr = ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=3,
        verbose=1
    )

    history = model.fit(
        X_train, y_train,
        epochs=epochs,
        batch_size=32,
        validation_split=0.1,
        callbacks=[reduce_lr],
        verbose=1
    )
    return history


def evaluate_and_plot(model, scaler, X_test, y_test, data, train_size, window_size, ticker):
    """Evalúa el modelo, calcula baselines y dibuja gráficas."""
    # Predicción del LSTM en test (escala [0,1])
    y_pred_scaled = model.predict(X_test)

    # Desescalar a precios reales
    y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
    y_test_real = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()

    # ---------- Baseline 1: ingenuo (mañana = hoy) ----------
    y_test_real_shifted = y_test_real[1:]      # targets desde el segundo día
    y_pred_naive = y_test_real[:-1]            # predicción = valor del día previo

    mae_naive = mean_absolute_error(y_test_real_shifted, y_pred_naive)
    rmse_naive = np.sqrt(mean_squared_error(y_test_real_shifted, y_pred_naive))

    # ---------- Baseline 2: media móvil de 5 días ----------
    window = 5
    ma_preds = []
    ma_targets = []

    for i in range(window, len(y_test_real)):
        ma_preds.append(y_test_real[i-window:i].mean())
        ma_targets.append(y_test_real[i])

    ma_preds = np.array(ma_preds)
    ma_targets = np.array(ma_targets)

    mae_ma5 = mean_absolute_error(ma_targets, ma_preds)
    rmse_ma5 = np.sqrt(mean_squared_error(ma_targets, ma_preds))

    # ---------- Métricas del LSTM ----------
    mae_lstm = mean_absolute_error(y_test_real, y_pred)
    rmse_lstm = np.sqrt(mean_squared_error(y_test_real, y_pred))

    print("===== MÉTRICAS EN TEST =====")
    print(f"Baseline ingenuo (mañana = hoy)     -> MAE: {mae_naive:.4f} | RMSE: {rmse_naive:.4f}")
    print(f"Baseline media móvil 5 días         -> MAE: {mae_ma5:.4f} | RMSE: {rmse_ma5:.4f}")
    print(f"Modelo LSTM                         -> MAE: {mae_lstm:.4f} | RMSE: {rmse_lstm:.4f}")

    # Fechas correspondientes al conjunto de test
    fechas = data.index[window_size + train_size : window_size + train_size + len(y_test_real)]

    # Gráfica predicción vs real
    plt.figure(figsize=(12,4))
    plt.plot(fechas, y_test_real, label="Real")
    plt.plot(fechas, y_pred, label="Predicción LSTM")
    plt.title(f"Predicción vs Real – LSTM ({ticker}) desde pandemia")
    plt.xlabel("Fecha")
    plt.ylabel("Precio de cierre")
    plt.legend()
    plt.show()

    return mae_lstm, rmse_lstm


def predict_next_day_close(model, scaler, close_prices, window_size):
    """
    last_60_closes: usamos los últimos 60 precios de cierre reales.
    Devuelve la predicción del cierre del próximo día.
    """
    last_60 = close_prices[-window_size:]
    arr_scaled = scaler.transform(last_60.reshape(-1,1))
    X_input = arr_scaled.reshape(1, window_size, 1)
    pred_scaled = model.predict(X_input)[0,0]
    pred_price = scaler.inverse_transform([[pred_scaled]])[0,0]
    return pred_price


# ===========================
# 4. Función principal
# ===========================
def main():
    print("TensorFlow:", tf.__version__)
    print(f"\nTicker: {TICKER} | start_date: {START_DATE} | epochs: {EPOCHS}\n")

    # Preparar datos
    (data, close_prices, scaler,
     X_train, y_train, X_test, y_test,
     train_size, window_size) = prepare_data(TICKER, START_DATE)

    # Construir modelo
    model = build_model(window_size)
    model.summary()

    # Entrenar modelo
    history = train_model(model, X_train, y_train, EPOCHS)

    # Curvas de pérdida
    plt.plot(history.history['loss'], label='Train')
    plt.plot(history.history['val_loss'], label='Val')
    plt.title("Pérdida durante el entrenamiento")
    plt.xlabel("Época")
    plt.ylabel("MSE")
    plt.legend()
    plt.show()

    # Evaluar en test y mostrar baselines
    evaluate_and_plot(model, scaler, X_test, y_test, data, train_size, window_size, TICKER)

    # Predicción del cierre de HOY usando últimos 60 cierres (hasta AYER)
    prediccion_manana = predict_next_day_close(model, scaler, close_prices, window_size)

    print("\nPrecio de cierre del último día disponible (AYER):", close_prices[-1,0])
    print("Predicción de cierre para el próximo día (HOY):", prediccion_manana)


# ===========================
# 5. Punto de entrada
# ===========================
if __name__ == "__main__":
    main()

"""**interfaz CLI**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile prediccion_precio_accion_IA.py
# # -*- coding: utf-8 -*-
# """prediccion_precio_accion_IA.py"""
# 
# import yfinance as yf
# import numpy as np
# import matplotlib.pyplot as plt
# 
# from sklearn.preprocessing import MinMaxScaler
# from sklearn.metrics import mean_absolute_error, mean_squared_error
# 
# import tensorflow as tf
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import LSTM, Dense, Dropout
# from tensorflow.keras.callbacks import ReduceLROnPlateau
# 
# from datetime import date
# import argparse
# import sys
# 
# plt.rcParams['figure.figsize'] = (12,4)
# 
# # ===========================
# # 2. Parámetros por línea de comandos
# # ===========================
# parser = argparse.ArgumentParser(description="Predicción de precio de cierre con LSTM")
# 
# parser.add_argument(
#     "--ticker",
#     type=str,
#     default="AAPL",
#     help="Ticker de la acción a predecir (ej: AAPL, MSFT, TSLA)"
# )
# 
# parser.add_argument(
#     "--start_date",
#     type=str,
#     default="2020-03-01",
#     help="Fecha inicial para descargar datos históricos (YYYY-MM-DD)"
# )
# 
# parser.add_argument(
#     "--epochs",
#     type=int,
#     default=80,
#     help="Número de épocas para entrenar el modelo"
# )
# 
# # En notebooks (Colab/Jupyter) ignoramos los argumentos del sistema
# if 'ipykernel' in sys.modules:
#     args = parser.parse_args(args=[])
# else:
#     args = parser.parse_args()
# 
# TICKER = args.ticker
# START_DATE = args.start_date
# EPOCHS = args.epochs
# 
# # ===========================
# # 3. Funciones auxiliares
# # ===========================
# def create_sequences(series, window):
#     """Crea secuencias de longitud 'window' para predicción un paso adelante."""
#     X, y = [], []
#     for i in range(window, len(series)):
#         X.append(series[i-window:i, 0])   # últimos 'window' precios
#         y.append(series[i, 0])           # siguiente precio
#     X = np.array(X)
#     y = np.array(y)
#     return X, y
# 
# 
# def prepare_data(ticker, start_date, window_size=60):
#     """
#     Descarga datos hasta AYER, escala, crea secuencias y hace split train/test.
#     Devuelve: data, close_prices, scaler, X_train, y_train, X_test, y_test, train_size, window_size
#     """
#     today = date.today()
#     end_date = today.strftime("%Y-%m-%d")  # yfinance usa end como exclusivo → llega hasta ayer
# 
#     data = yf.download(ticker, start=start_date, end=end_date)
#     data = data[['Close']].copy()
# 
#     print(data.tail())
#     print("Número de días:", len(data))
#     print("Último cierre disponible (debe ser AYER):", data['Close'].iloc[-1])
# 
#     close_prices = data['Close'].values.reshape(-1,1)
# 
#     scaler = MinMaxScaler(feature_range=(0,1))
#     close_scaled = scaler.fit_transform(close_prices)
# 
#     X_all, y_all = create_sequences(close_scaled, window_size)
#     X_all = np.expand_dims(X_all, axis=-1)  # (n_samples, window_size, 1)
# 
#     print("X_all shape:", X_all.shape)
#     print("y_all shape:", y_all.shape)
# 
#     train_size = int(len(X_all) * 0.8)
#     X_train = X_all[:train_size]
#     y_train = y_all[:train_size]
#     X_test  = X_all[train_size:]
#     y_test  = y_all[train_size:]
# 
#     print("Train:", X_train.shape, "Test:", X_test.shape)
# 
#     return data, close_prices, scaler, X_train, y_train, X_test, y_test, train_size, window_size
# 
# 
# def build_model(window_size):
#     """Define y compila el modelo LSTM."""
#     model = Sequential([
#         LSTM(128, return_sequences=True, input_shape=(window_size, 1)),
#         Dropout(0.2),
#         LSTM(64),
#         Dropout(0.2),
#         Dense(1)
#     ])
# 
#     model.compile(
#         loss='mean_squared_error',
#         optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)
#     )
# 
#     return model
# 
# 
# def train_model(model, X_train, y_train, epochs):
#     """Entrena el modelo LSTM y devuelve el history."""
#     reduce_lr = ReduceLROnPlateau(
#         monitor='val_loss',
#         factor=0.5,
#         patience=3,
#         verbose=1
#     )
# 
#     history = model.fit(
#         X_train, y_train,
#         epochs=epochs,
#         batch_size=32,
#         validation_split=0.1,
#         callbacks=[reduce_lr],
#         verbose=1
#     )
#     return history
# 
# 
# def evaluate_and_plot(model, scaler, X_test, y_test, data, train_size, window_size, ticker):
#     """Evalúa el modelo, calcula baselines y dibuja gráficas."""
#     # Predicción del LSTM en test (escala [0,1])
#     y_pred_scaled = model.predict(X_test)
# 
#     # Desescalar a precios reales
#     y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
#     y_test_real = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
# 
#     # ---------- Baseline 1: ingenuo (mañana = hoy) ----------
#     y_test_real_shifted = y_test_real[1:]      # targets desde el segundo día
#     y_pred_naive = y_test_real[:-1]            # predicción = valor del día previo
# 
#     mae_naive = mean_absolute_error(y_test_real_shifted, y_pred_naive)
#     rmse_naive = np.sqrt(mean_squared_error(y_test_real_shifted, y_pred_naive))
# 
#     # ---------- Baseline 2: media móvil de 5 días ----------
#     window = 5
#     ma_preds = []
#     ma_targets = []
# 
#     for i in range(window, len(y_test_real)):
#         ma_preds.append(y_test_real[i-window:i].mean())
#         ma_targets.append(y_test_real[i])
# 
#     ma_preds = np.array(ma_preds)
#     ma_targets = np.array(ma_targets)
# 
#     mae_ma5 = mean_absolute_error(ma_targets, ma_preds)
#     rmse_ma5 = np.sqrt(mean_squared_error(ma_targets, ma_preds))
# 
#     # ---------- Métricas del LSTM ----------
#     mae_lstm = mean_absolute_error(y_test_real, y_pred)
#     rmse_lstm = np.sqrt(mean_squared_error(y_test_real, y_pred))
# 
#     print("===== MÉTRICAS EN TEST =====")
#     print(f"Baseline ingenuo (mañana = hoy)     -> MAE: {mae_naive:.4f} | RMSE: {rmse_naive:.4f}")
#     print(f"Baseline media móvil 5 días         -> MAE: {mae_ma5:.4f} | RMSE: {rmse_ma5:.4f}")
#     print(f"Modelo LSTM                         -> MAE: {mae_lstm:.4f} | RMSE: {rmse_lstm:.4f}")
# 
#     # Fechas correspondientes al conjunto de test
#     fechas = data.index[window_size + train_size : window_size + train_size + len(y_test_real)]
# 
#     # Gráfica predicción vs real
#     plt.figure(figsize=(12,4))
#     plt.plot(fechas, y_test_real, label="Real")
#     plt.plot(fechas, y_pred, label="Predicción LSTM")
#     plt.title(f"Predicción vs Real – LSTM ({ticker}) desde pandemia")
#     plt.xlabel("Fecha")
#     plt.ylabel("Precio de cierre")
#     plt.legend()
#     plt.show()
# 
#     return mae_lstm, rmse_lstm
# 
# 
# def predict_next_day_close(model, scaler, close_prices, window_size):
#     """Devuelve la predicción del cierre del próximo día usando los últimos 60 cierres."""
#     last_60 = close_prices[-window_size:]
#     arr_scaled = scaler.transform(last_60.reshape(-1,1))
#     X_input = arr_scaled.reshape(1, window_size, 1)
#     pred_scaled = model.predict(X_input)[0,0]
#     pred_price = scaler.inverse_transform([[pred_scaled]])[0,0]
#     return pred_price
# 
# 
# # ===========================
# # 4. Función principal
# # ===========================
# def main():
#     print("TensorFlow:", tf.__version__)
#     print(f"\nTicker: {TICKER} | start_date: {START_DATE} | epochs: {EPOCHS}\n")
# 
#     # Preparar datos
#     (data, close_prices, scaler,
#      X_train, y_train, X_test, y_test,
#      train_size, window_size) = prepare_data(TICKER, START_DATE)
# 
#     # Construir modelo
#     model = build_model(window_size)
#     model.summary()
# 
#     # Entrenar modelo
#     history = train_model(model, X_train, y_train, EPOCHS)
# 
#     # Curvas de pérdida
#     plt.plot(history.history['loss'], label='Train')
#     plt.plot(history.history['val_loss'], label='Val')
#     plt.title("Pérdida durante el entrenamiento")
#     plt.xlabel("Época")
#     plt.ylabel("MSE")
#     plt.legend()
#     plt.show()
# 
#     # Evaluar en test y mostrar baselines
#     evaluate_and_plot(model, scaler, X_test, y_test, data, train_size, window_size, TICKER)
# 
#     # Predicción del cierre de HOY usando últimos 60 cierres (hasta AYER)
#     prediccion_manana = predict_next_day_close(model, scaler, close_prices, window_size)
# 
#     print("\nPrecio de cierre del último día disponible (AYER):", close_prices[-1,0])
#     print("Predicción de cierre para el próximo día (HOY):", prediccion_manana)
# 
# 
# # ===========================
# # 5. Punto de entrada
# # ===========================
# if __name__ == "__main__":
#     main()
#

!python prediccion_precio_accion_IA.py --ticker NVDA --epochs 50

import argparse
from prediccion_precio_accion_ia import predict_next_day_close, train_model

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--ticker", default="AAPL")
    parser.add_argument("--mode", choices=["train", "predict"], required=True)
    args = parser.parse_args()

    if args.mode == "train":
        train_model(args.ticker)
    elif args.mode == "predict":
        pred = predict_next_day_close(args.ticker)
        print(f"Predicción de cierre de HOY para {args.ticker}: {pred}")

if __name__ == "__main__":
    main()
